{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing for Different Types of Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith supports many different types of Runs - you can specify what type your Run is in the @traceable decorator. The types of runs are:\n",
    "\n",
    "- LLM: Invokes an LLM\n",
    "- Retriever: Retrieves documents from databases or other sources\n",
    "- Tool: Executes actions with function calls\n",
    "- Chain: Default type; combines multiple Runs into a larger process\n",
    "- Prompt: Hydrates a prompt to be used with an LLM\n",
    "- Parser: Extracts structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline!\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Runs for Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith provides special rendering and processing for LLM traces. In order to make the most of this feature, you must log your LLM traces in a specific format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For chat-style models, inputs must be a list of messages in OpenAI-compatible format, represented as Python dictionaries or TypeScript object. Each message must contain the key role and content.\n",
    "\n",
    "The output is accepted in any of the following formats:\n",
    "\n",
    "- A dictionary/object that contains the key choices with a value that is a list of dictionaries/objects. Each dictionary/object must contain the key message, which maps to a message object with the keys role and content.\n",
    "- A dictionary/object that contains the key message with a value that is a message object with the keys role and content.\n",
    "- A tuple/array of two elements, where the first element is the role and the second element is the content.\n",
    "- A dictionary/object that contains the key role and content.\n",
    "The input to your function should be named messages.\n",
    "\n",
    "You can also provide the following metadata fields to help LangSmith identify the model and calculate costs. If using LangChain or OpenAI wrapper, these fields will be automatically populated correctly.\n",
    "- ls_provider: The provider of the model, eg \"openai\", \"anthropic\", etc.\n",
    "- ls_model_name: The name of the model, eg \"gpt-4o-mini\", \"claude-3-opus-20240307\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'message': {'role': 'assistant',\n",
       "    'content': 'A dictionary comprehension is a concise way to create dictionaries in Python. It follows the syntax {key: value for item in iterable}. For example, {x: x**2 for x in range(5)} creates a dictionary mapping numbers to their squares.'}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "# Custom input for a tutoring assistant scenario\n",
    "inputs = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful programming tutor specializing in Python.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Can you explain what a dictionary comprehension is?\"},\n",
    "]\n",
    "\n",
    "# Custom output for the tutoring scenario\n",
    "output = {\n",
    "  \"choices\": [\n",
    "      {\n",
    "          \"message\": {\n",
    "              \"role\": \"assistant\", \n",
    "              \"content\": \"A dictionary comprehension is a concise way to create dictionaries in Python. It follows the syntax {key: value for item in iterable}. For example, {x: x**2 for x in range(5)} creates a dictionary mapping numbers to their squares.\"\n",
    "          }\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Can also use one of:\n",
    "# output = {\n",
    "#     \"message\": {\n",
    "#         \"role\": \"assistant\",\n",
    "#         \"content\": \"A dictionary comprehension is a concise way to create dictionaries...\"\n",
    "#     }\n",
    "# }\n",
    "#\n",
    "# output = {\n",
    "#     \"role\": \"assistant\",\n",
    "#     \"content\": \"A dictionary comprehension is a concise way to create dictionaries...\"\n",
    "# }\n",
    "#\n",
    "# output = [\"assistant\", \"A dictionary comprehension is a concise way to create dictionaries...\"]\n",
    "\n",
    "@traceable(\n",
    "  # TODO: Add an run_type=\"llm\", and metadata for ls_provider, and ls_model_name\n",
    "  run_type=\"llm\",\n",
    "  metadata={\"ls_provider\": \"custom_tutor\", \"ls_model_name\": \"python_tutor_v1\", \"subject\": \"programming\"}\n",
    ")\n",
    "def programming_tutor_chat(messages: list):\n",
    "  return output\n",
    "\n",
    "programming_tutor_chat(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Streaming LLM Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For streaming, you can \"reduce\" the outputs into the same format as the non-streaming version. This is currently only supported in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'choices': [{'message': {'content': 'Great question! ',\n",
       "     'role': 'assistant'}}]},\n",
       " {'choices': [{'message': {'content': 'Let me break this down for you step by step...',\n",
       "     'role': 'assistant'}}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _reduce_study_chunks(chunks: list):\n",
    "    all_text = \"\".join([chunk[\"choices\"][0][\"message\"][\"content\"] for chunk in chunks])\n",
    "    return {\"choices\": [{\"message\": {\"content\": all_text, \"role\": \"assistant\"}}]}\n",
    "\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"study_assistant\", \"ls_model_name\": \"streaming_tutor\", \"mode\": \"interactive\"},\n",
    "    # TODO: Add a reduce_fn\n",
    "    reduce_fn=_reduce_study_chunks,\n",
    ")\n",
    "def my_streaming_study_assistant(messages: list):\n",
    "    # Simulate streaming response for study assistance\n",
    "    for chunk in [\"Great question! \", \"Let me break this down for you step by step...\"]:\n",
    "        yield {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"message\": {\n",
    "                        \"content\": chunk,\n",
    "                        \"role\": \"assistant\",\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "list(\n",
    "    my_streaming_study_assistant(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful study assistant. Break down complex topics clearly.\"},\n",
    "            {\"role\": \"user\", \"content\": \"machine learning concepts\"},\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Runs + Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many LLM applications require looking up documents from vector databases, knowledge graphs, or other types of indexes. Retriever traces are a way to log the documents that are retrieved by the retriever. LangSmith provides special rendering for retrieval steps in traces to make it easier to understand and diagnose retrieval issues. In order for retrieval steps to be rendered correctly, a few small steps need to be taken.\n",
    "\n",
    "1. Annotate the retriever step with run_type=\"retriever\".\n",
    "2. Return a list of Python dictionaries or TypeScript objects from the retriever step. Each dictionary should contain the following keys:\n",
    "    - page_content: The text of the document.\n",
    "    - type: This should always be \"Document\".\n",
    "    - metadata: A python dictionary or TypeScript object containing metadata about the document. This metadata will be displayed in the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_content': 'Python functions are reusable blocks of code that perform specific tasks',\n",
       "  'type': 'Document',\n",
       "  'metadata': {'subject': 'computer_science',\n",
       "   'difficulty': 'beginner',\n",
       "   'source': 'custom_db'}},\n",
       " {'page_content': 'Variables in Python are containers for storing data values',\n",
       "  'type': 'Document',\n",
       "  'metadata': {'subject': 'computer_science',\n",
       "   'difficulty': 'beginner',\n",
       "   'source': 'custom_db'}},\n",
       " {'page_content': 'Loops allow you to execute code repeatedly based on certain conditions',\n",
       "  'type': 'Document',\n",
       "  'metadata': {'subject': 'computer_science',\n",
       "   'difficulty': 'beginner',\n",
       "   'source': 'custom_db'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "def _convert_study_docs(results):\n",
    "  return [\n",
    "      {\n",
    "          \"page_content\": r,\n",
    "          \"type\": \"Document\", # This is the correct format for document type\n",
    "          \"metadata\": {\"subject\": \"computer_science\", \"difficulty\": \"beginner\", \"source\": \"custom_db\"}\n",
    "      }\n",
    "      for r in results\n",
    "  ]\n",
    "\n",
    "@traceable(\n",
    "    # TODO: Add an run_type=\"retriever\"\n",
    "    run_type=\"retriever\",\n",
    "    metadata={\"database_type\": \"educational_content\", \"retrieval_method\": \"semantic_search\"}\n",
    ")\n",
    "def retrieve_study_materials(query):\n",
    "  # Custom retriever returning educational content about programming\n",
    "  # In production, this could be a real educational database or knowledge base\n",
    "  contents = [\n",
    "      \"Python functions are reusable blocks of code that perform specific tasks\",\n",
    "      \"Variables in Python are containers for storing data values\", \n",
    "      \"Loops allow you to execute code repeatedly based on certain conditions\"\n",
    "  ]\n",
    "  return _convert_study_docs(contents)\n",
    "\n",
    "retrieve_study_materials(\"Python programming basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith has custom rendering for Tool Calls made by the model to make it clear when provided tools are being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CMwPcZ6fLmx5pLFUqYAqOFvxhW3Xo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Recursion in Python is considered an advanced topic. It involves functions that call themselves to solve problems, which can be quite powerful but also complex. If you're comfortable with basic programming concepts like functions, loops, and data structures, you might be ready to tackle recursion. However, if you're still getting familiar with these foundational concepts, it might be beneficial to strengthen those skills first before diving into recursion. Would you like some resources or a brief overview of recursion?\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759583788, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=91, prompt_tokens=104, total_tokens=195, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "@traceable(\n",
    "  # TODO: Add an run_type=\"tool\"\n",
    "  run_type=\"tool\",\n",
    "  metadata={\"tool_category\": \"educational\", \"subject\": \"programming\"}\n",
    ")\n",
    "def get_coding_difficulty(topic: str, language: str):\n",
    "    \"\"\"Tool to assess the difficulty level of a programming topic\"\"\"\n",
    "    difficulty_map = {\n",
    "        \"variables\": \"beginner\",\n",
    "        \"functions\": \"beginner\", \n",
    "        \"loops\": \"intermediate\",\n",
    "        \"recursion\": \"advanced\",\n",
    "        \"algorithms\": \"advanced\"\n",
    "    }\n",
    "    return difficulty_map.get(topic.lower(), \"intermediate\")\n",
    "\n",
    "@traceable(run_type=\"llm\", metadata={\"purpose\": \"educational_assistant\"})\n",
    "def call_openai_tutor(\n",
    "    messages: List[dict], tools: Optional[List[dict]]\n",
    ") -> str:\n",
    "  return openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.2,  # Slightly higher for more creative educational responses\n",
    "    tools=tools\n",
    "  )\n",
    "\n",
    "@traceable(run_type=\"chain\", metadata={\"workflow\": \"educational_assessment\"})\n",
    "def assess_learning_topic(inputs, tools):\n",
    "  response = call_openai_tutor(inputs, tools)\n",
    "  tool_call_args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "  topic = tool_call_args[\"topic\"]\n",
    "  language = tool_call_args[\"language\"]\n",
    "  tool_response_message = {\n",
    "    \"role\": \"tool\",\n",
    "    \"content\": json.dumps({\n",
    "        \"topic\": topic,\n",
    "        \"language\": language,\n",
    "        \"difficulty\": get_coding_difficulty(topic, language),\n",
    "        \"recommendation\": f\"This is a {get_coding_difficulty(topic, language)} level topic in {language}\"\n",
    "    }),\n",
    "    \"tool_call_id\": response.choices[0].message.tool_calls[0].id\n",
    "  }\n",
    "  inputs.append(response.choices[0].message)\n",
    "  inputs.append(tool_response_message)\n",
    "  output = call_openai_tutor(inputs, None)\n",
    "  return output\n",
    "\n",
    "# Custom tools for educational assessment\n",
    "educational_tools = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_coding_difficulty\",\n",
    "        \"description\": \"Assess the difficulty level of a programming topic for learning purposes\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"topic\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The programming topic to assess, e.g., variables, functions, loops\"\n",
    "            },\n",
    "            \"language\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"Python\", \"JavaScript\", \"Java\", \"C++\"],\n",
    "              \"description\": \"The programming language context\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"topic\", \"language\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Custom input for educational assessment\n",
    "educational_inputs = [\n",
    "  {\"role\": \"system\", \"content\": \"You are an educational assistant that helps assess programming topics.\"},\n",
    "  {\"role\": \"user\", \"content\": \"I want to learn about recursion in Python. Is it suitable for my level?\"},\n",
    "]\n",
    "\n",
    "assess_learning_topic(educational_inputs, educational_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
